{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T13:55:41.220246900Z",
     "start_time": "2024-01-06T13:55:36.039226200Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import keras\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T13:39:57.125128100Z",
     "start_time": "2024-01-06T13:39:57.060956100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>name</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>roshan</td>\n",
       "      <td>619</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>lodha</td>\n",
       "      <td>608</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>garcia</td>\n",
       "      <td>502</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>paud</td>\n",
       "      <td>699</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>kalbhor</td>\n",
       "      <td>850</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>zahaldar</td>\n",
       "      <td>645</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>tamhankar</td>\n",
       "      <td>822</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>vichare</td>\n",
       "      <td>376</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>girdhar</td>\n",
       "      <td>501</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>shetty</td>\n",
       "      <td>684</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId       name  CreditScore  Geography  Gender  Age  \\\n",
       "0          1    15634602     roshan          619    Chennai  Female   42   \n",
       "1          2    15647311      lodha          608  Bangalore  Female   41   \n",
       "2          3    15619304     garcia          502    Chennai  Female   42   \n",
       "3          4    15701354       paud          699    Chennai  Female   39   \n",
       "4          5    15737888    kalbhor          850  Bangalore  Female   43   \n",
       "5          6    15574012   zahaldar          645  Bangalore    Male   44   \n",
       "6          7    15592531  tamhankar          822    Chennai    Male   50   \n",
       "7          8    15656148    vichare          376     Mumbai  Female   29   \n",
       "8          9    15792365    girdhar          501    Chennai    Male   44   \n",
       "9         10    15592389     shetty          684    Chennai    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "5       8  113755.78              2          1               0   \n",
       "6       7       0.00              2          1               1   \n",
       "7       4  115046.74              4          1               0   \n",
       "8       4  142051.07              2          0               1   \n",
       "9       2  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data into a dataframe\n",
    "data = pd.read_csv(\"data/Churn_Modelling.csv\")\n",
    "# display the dataframe\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T13:40:33.942208900Z",
     "start_time": "2024-01-06T13:40:33.915940Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading the data into a dataframe\n",
    "data = pd.read_csv(\"data/Churn_Modelling.csv\")\n",
    "\n",
    "# split the dataframe into dependent and independent variables\n",
    "X = data.iloc[:, 3:13].values\n",
    "y =data.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T13:40:36.890549400Z",
     "start_time": "2024-01-06T13:40:36.876445400Z"
    }
   },
   "outputs": [],
   "source": [
    "# encode the gender column\n",
    "label_encoder_gender = LabelEncoder()\n",
    "X[:, 2] = label_encoder_gender.fit_transform(X[:, 2])\n",
    "# encode the geography column\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(drop='first'), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "## recorded information\n",
    "# female = 0, male = 1\n",
    "# Chennai = [1,0], Bangalore = [0,0], Mumbai = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T13:40:37.907816400Z",
     "start_time": "2024-01-06T13:40:37.884199700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/scaler_instance.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the dependent and independent variables into \n",
    "# training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "# scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# save the scaler instance to be called in the future\n",
    "dump(scaler, \"model/scaler_instance.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T13:41:56.136307200Z",
     "start_time": "2024-01-06T13:40:38.533880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From c:\\Users\\Jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Jacob\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "320/320 [==============================] - 1s 906us/step - loss: 0.5826 - accuracy: 0.7519\n",
      "Epoch 2/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.4807 - accuracy: 0.7983\n",
      "Epoch 3/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.4627 - accuracy: 0.7983\n",
      "Epoch 4/500\n",
      "320/320 [==============================] - 0s 898us/step - loss: 0.4553 - accuracy: 0.7983\n",
      "Epoch 5/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.4502 - accuracy: 0.7983\n",
      "Epoch 6/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.4460 - accuracy: 0.7983\n",
      "Epoch 7/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.4438 - accuracy: 0.7983\n",
      "Epoch 8/500\n",
      "320/320 [==============================] - 0s 879us/step - loss: 0.4417 - accuracy: 0.7983\n",
      "Epoch 9/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.4407 - accuracy: 0.7983\n",
      "Epoch 10/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.4396 - accuracy: 0.7983\n",
      "Epoch 11/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.4354 - accuracy: 0.7983\n",
      "Epoch 12/500\n",
      "320/320 [==============================] - 0s 830us/step - loss: 0.4365 - accuracy: 0.7983\n",
      "Epoch 13/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4365 - accuracy: 0.7983\n",
      "Epoch 14/500\n",
      "320/320 [==============================] - 0s 897us/step - loss: 0.4346 - accuracy: 0.7983\n",
      "Epoch 15/500\n",
      "320/320 [==============================] - 0s 853us/step - loss: 0.4325 - accuracy: 0.7983\n",
      "Epoch 16/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.4317 - accuracy: 0.7983\n",
      "Epoch 17/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.4309 - accuracy: 0.7983\n",
      "Epoch 18/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.4309 - accuracy: 0.7983\n",
      "Epoch 19/500\n",
      "320/320 [==============================] - 0s 929us/step - loss: 0.4299 - accuracy: 0.8059\n",
      "Epoch 20/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.4285 - accuracy: 0.8151\n",
      "Epoch 21/500\n",
      "320/320 [==============================] - 0s 887us/step - loss: 0.4306 - accuracy: 0.8152\n",
      "Epoch 22/500\n",
      "320/320 [==============================] - 0s 904us/step - loss: 0.4292 - accuracy: 0.8161\n",
      "Epoch 23/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.4296 - accuracy: 0.8169\n",
      "Epoch 24/500\n",
      "320/320 [==============================] - 0s 958us/step - loss: 0.4283 - accuracy: 0.8164\n",
      "Epoch 25/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.4261 - accuracy: 0.8183\n",
      "Epoch 26/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.4252 - accuracy: 0.8196\n",
      "Epoch 27/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.4252 - accuracy: 0.8209\n",
      "Epoch 28/500\n",
      "320/320 [==============================] - 0s 869us/step - loss: 0.4257 - accuracy: 0.8221\n",
      "Epoch 29/500\n",
      "320/320 [==============================] - 0s 885us/step - loss: 0.4270 - accuracy: 0.8230\n",
      "Epoch 30/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.4237 - accuracy: 0.8264\n",
      "Epoch 31/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.4225 - accuracy: 0.8232\n",
      "Epoch 32/500\n",
      "320/320 [==============================] - 0s 919us/step - loss: 0.4228 - accuracy: 0.8251\n",
      "Epoch 33/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.4252 - accuracy: 0.8267\n",
      "Epoch 34/500\n",
      "320/320 [==============================] - 0s 897us/step - loss: 0.4220 - accuracy: 0.8276\n",
      "Epoch 35/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.4183 - accuracy: 0.8270\n",
      "Epoch 36/500\n",
      "320/320 [==============================] - 0s 916us/step - loss: 0.4220 - accuracy: 0.8267\n",
      "Epoch 37/500\n",
      "320/320 [==============================] - 0s 888us/step - loss: 0.4214 - accuracy: 0.8264\n",
      "Epoch 38/500\n",
      "320/320 [==============================] - 0s 954us/step - loss: 0.4202 - accuracy: 0.8269\n",
      "Epoch 39/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.4187 - accuracy: 0.8254\n",
      "Epoch 40/500\n",
      "320/320 [==============================] - 0s 888us/step - loss: 0.4220 - accuracy: 0.8313\n",
      "Epoch 41/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.4211 - accuracy: 0.8286\n",
      "Epoch 42/500\n",
      "320/320 [==============================] - 0s 894us/step - loss: 0.4203 - accuracy: 0.8269\n",
      "Epoch 43/500\n",
      "320/320 [==============================] - 0s 951us/step - loss: 0.4173 - accuracy: 0.8303\n",
      "Epoch 44/500\n",
      "320/320 [==============================] - 0s 900us/step - loss: 0.4181 - accuracy: 0.8310\n",
      "Epoch 45/500\n",
      "320/320 [==============================] - 0s 894us/step - loss: 0.4212 - accuracy: 0.8263\n",
      "Epoch 46/500\n",
      "320/320 [==============================] - 0s 869us/step - loss: 0.4175 - accuracy: 0.8290\n",
      "Epoch 47/500\n",
      "320/320 [==============================] - 0s 924us/step - loss: 0.4187 - accuracy: 0.8311\n",
      "Epoch 48/500\n",
      "320/320 [==============================] - 0s 938us/step - loss: 0.4175 - accuracy: 0.8294\n",
      "Epoch 49/500\n",
      "320/320 [==============================] - 0s 879us/step - loss: 0.4171 - accuracy: 0.8315\n",
      "Epoch 50/500\n",
      "320/320 [==============================] - 0s 891us/step - loss: 0.4154 - accuracy: 0.8280\n",
      "Epoch 51/500\n",
      "320/320 [==============================] - 0s 904us/step - loss: 0.4179 - accuracy: 0.8306\n",
      "Epoch 52/500\n",
      "320/320 [==============================] - 0s 891us/step - loss: 0.4208 - accuracy: 0.8285\n",
      "Epoch 53/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.4164 - accuracy: 0.8271\n",
      "Epoch 54/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.4164 - accuracy: 0.8301\n",
      "Epoch 55/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.4166 - accuracy: 0.8314\n",
      "Epoch 56/500\n",
      "320/320 [==============================] - 0s 853us/step - loss: 0.4166 - accuracy: 0.8242\n",
      "Epoch 57/500\n",
      "320/320 [==============================] - 0s 894us/step - loss: 0.4160 - accuracy: 0.8286\n",
      "Epoch 58/500\n",
      "320/320 [==============================] - 0s 916us/step - loss: 0.4166 - accuracy: 0.8281\n",
      "Epoch 59/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.4142 - accuracy: 0.8319\n",
      "Epoch 60/500\n",
      "320/320 [==============================] - 0s 803us/step - loss: 0.4147 - accuracy: 0.8275\n",
      "Epoch 61/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.4129 - accuracy: 0.8261\n",
      "Epoch 62/500\n",
      "320/320 [==============================] - 0s 875us/step - loss: 0.4195 - accuracy: 0.8271\n",
      "Epoch 63/500\n",
      "320/320 [==============================] - 0s 868us/step - loss: 0.4153 - accuracy: 0.8294\n",
      "Epoch 64/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.4137 - accuracy: 0.8253\n",
      "Epoch 65/500\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8281\n",
      "Epoch 66/500\n",
      "320/320 [==============================] - 0s 916us/step - loss: 0.4110 - accuracy: 0.8326\n",
      "Epoch 67/500\n",
      "320/320 [==============================] - 0s 885us/step - loss: 0.4152 - accuracy: 0.8273\n",
      "Epoch 68/500\n",
      "320/320 [==============================] - 0s 845us/step - loss: 0.4124 - accuracy: 0.8296\n",
      "Epoch 69/500\n",
      "320/320 [==============================] - 0s 840us/step - loss: 0.4108 - accuracy: 0.8282\n",
      "Epoch 70/500\n",
      "320/320 [==============================] - 0s 852us/step - loss: 0.4121 - accuracy: 0.8286\n",
      "Epoch 71/500\n",
      "320/320 [==============================] - 0s 800us/step - loss: 0.4122 - accuracy: 0.8299\n",
      "Epoch 72/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.4136 - accuracy: 0.8310\n",
      "Epoch 73/500\n",
      "320/320 [==============================] - 0s 914us/step - loss: 0.4073 - accuracy: 0.8304\n",
      "Epoch 74/500\n",
      "320/320 [==============================] - 0s 918us/step - loss: 0.4134 - accuracy: 0.8256\n",
      "Epoch 75/500\n",
      "320/320 [==============================] - 0s 864us/step - loss: 0.4092 - accuracy: 0.8285\n",
      "Epoch 76/500\n",
      "320/320 [==============================] - 0s 870us/step - loss: 0.4160 - accuracy: 0.8278\n",
      "Epoch 77/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.4110 - accuracy: 0.8292\n",
      "Epoch 78/500\n",
      "320/320 [==============================] - 0s 842us/step - loss: 0.4114 - accuracy: 0.8267\n",
      "Epoch 79/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4125 - accuracy: 0.8290\n",
      "Epoch 80/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.4114 - accuracy: 0.8298\n",
      "Epoch 81/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.4085 - accuracy: 0.8324\n",
      "Epoch 82/500\n",
      "320/320 [==============================] - 0s 843us/step - loss: 0.4120 - accuracy: 0.8321\n",
      "Epoch 83/500\n",
      "320/320 [==============================] - 0s 877us/step - loss: 0.4088 - accuracy: 0.8324\n",
      "Epoch 84/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.4112 - accuracy: 0.8304\n",
      "Epoch 85/500\n",
      "320/320 [==============================] - 0s 929us/step - loss: 0.4091 - accuracy: 0.8334\n",
      "Epoch 86/500\n",
      "320/320 [==============================] - 0s 830us/step - loss: 0.4083 - accuracy: 0.8338\n",
      "Epoch 87/500\n",
      "320/320 [==============================] - 0s 845us/step - loss: 0.4079 - accuracy: 0.8310\n",
      "Epoch 88/500\n",
      "320/320 [==============================] - 0s 837us/step - loss: 0.4058 - accuracy: 0.8331\n",
      "Epoch 89/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.4106 - accuracy: 0.8324\n",
      "Epoch 90/500\n",
      "320/320 [==============================] - 0s 910us/step - loss: 0.4127 - accuracy: 0.8295\n",
      "Epoch 91/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.4105 - accuracy: 0.8296\n",
      "Epoch 92/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.4116 - accuracy: 0.8285\n",
      "Epoch 93/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.4095 - accuracy: 0.8324\n",
      "Epoch 94/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4064 - accuracy: 0.8378\n",
      "Epoch 95/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4093 - accuracy: 0.8316\n",
      "Epoch 96/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.4051 - accuracy: 0.8344\n",
      "Epoch 97/500\n",
      "320/320 [==============================] - 0s 888us/step - loss: 0.4102 - accuracy: 0.8314\n",
      "Epoch 98/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4102 - accuracy: 0.8329\n",
      "Epoch 99/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.4085 - accuracy: 0.8330\n",
      "Epoch 100/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.4099 - accuracy: 0.8325\n",
      "Epoch 101/500\n",
      "320/320 [==============================] - 0s 845us/step - loss: 0.4088 - accuracy: 0.8347\n",
      "Epoch 102/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.4072 - accuracy: 0.8321\n",
      "Epoch 103/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.4036 - accuracy: 0.8357\n",
      "Epoch 104/500\n",
      "320/320 [==============================] - 0s 875us/step - loss: 0.4031 - accuracy: 0.8359\n",
      "Epoch 105/500\n",
      "320/320 [==============================] - 0s 845us/step - loss: 0.4055 - accuracy: 0.8339\n",
      "Epoch 106/500\n",
      "320/320 [==============================] - 0s 845us/step - loss: 0.4111 - accuracy: 0.8347\n",
      "Epoch 107/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.4079 - accuracy: 0.8367\n",
      "Epoch 108/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.4039 - accuracy: 0.8364\n",
      "Epoch 109/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.4052 - accuracy: 0.8361\n",
      "Epoch 110/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.4077 - accuracy: 0.8370\n",
      "Epoch 111/500\n",
      "320/320 [==============================] - 0s 884us/step - loss: 0.4082 - accuracy: 0.8356\n",
      "Epoch 112/500\n",
      "320/320 [==============================] - 0s 866us/step - loss: 0.4059 - accuracy: 0.8357\n",
      "Epoch 113/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.4087 - accuracy: 0.8366\n",
      "Epoch 114/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.4074 - accuracy: 0.8382\n",
      "Epoch 115/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.4030 - accuracy: 0.8365\n",
      "Epoch 116/500\n",
      "320/320 [==============================] - 0s 913us/step - loss: 0.4045 - accuracy: 0.8361\n",
      "Epoch 117/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.4047 - accuracy: 0.8370\n",
      "Epoch 118/500\n",
      "320/320 [==============================] - 0s 870us/step - loss: 0.3993 - accuracy: 0.8411\n",
      "Epoch 119/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.4060 - accuracy: 0.8363\n",
      "Epoch 120/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4024 - accuracy: 0.8446\n",
      "Epoch 121/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.4047 - accuracy: 0.8420\n",
      "Epoch 122/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.4040 - accuracy: 0.8380\n",
      "Epoch 123/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3999 - accuracy: 0.8403\n",
      "Epoch 124/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.4033 - accuracy: 0.8396\n",
      "Epoch 125/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.4041 - accuracy: 0.8428\n",
      "Epoch 126/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.4040 - accuracy: 0.8364\n",
      "Epoch 127/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4007 - accuracy: 0.8424\n",
      "Epoch 128/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.4018 - accuracy: 0.8409\n",
      "Epoch 129/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3968 - accuracy: 0.8422\n",
      "Epoch 130/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.4019 - accuracy: 0.8438\n",
      "Epoch 131/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.4000 - accuracy: 0.8415\n",
      "Epoch 132/500\n",
      "320/320 [==============================] - 0s 861us/step - loss: 0.4003 - accuracy: 0.8396\n",
      "Epoch 133/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3999 - accuracy: 0.8418\n",
      "Epoch 134/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3977 - accuracy: 0.8446\n",
      "Epoch 135/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3969 - accuracy: 0.8450\n",
      "Epoch 136/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.4001 - accuracy: 0.8397\n",
      "Epoch 137/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3965 - accuracy: 0.8414\n",
      "Epoch 138/500\n",
      "320/320 [==============================] - 0s 871us/step - loss: 0.4011 - accuracy: 0.8418\n",
      "Epoch 139/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3950 - accuracy: 0.8406\n",
      "Epoch 140/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.4024 - accuracy: 0.8381\n",
      "Epoch 141/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3956 - accuracy: 0.8432\n",
      "Epoch 142/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3983 - accuracy: 0.8404\n",
      "Epoch 143/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3929 - accuracy: 0.8429\n",
      "Epoch 144/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3913 - accuracy: 0.8436\n",
      "Epoch 145/500\n",
      "320/320 [==============================] - 0s 861us/step - loss: 0.3965 - accuracy: 0.8416\n",
      "Epoch 146/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3922 - accuracy: 0.8441\n",
      "Epoch 147/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.4007 - accuracy: 0.8370\n",
      "Epoch 148/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3957 - accuracy: 0.8426\n",
      "Epoch 149/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3957 - accuracy: 0.8426\n",
      "Epoch 150/500\n",
      "320/320 [==============================] - 0s 827us/step - loss: 0.3936 - accuracy: 0.8422\n",
      "Epoch 151/500\n",
      "320/320 [==============================] - 0s 863us/step - loss: 0.3936 - accuracy: 0.8424\n",
      "Epoch 152/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3961 - accuracy: 0.8421\n",
      "Epoch 153/500\n",
      "320/320 [==============================] - 0s 929us/step - loss: 0.3929 - accuracy: 0.8420\n",
      "Epoch 154/500\n",
      "320/320 [==============================] - 0s 934us/step - loss: 0.3921 - accuracy: 0.8425\n",
      "Epoch 155/500\n",
      "320/320 [==============================] - 0s 894us/step - loss: 0.3960 - accuracy: 0.8405\n",
      "Epoch 156/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3958 - accuracy: 0.8440\n",
      "Epoch 157/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3913 - accuracy: 0.8424\n",
      "Epoch 158/500\n",
      "320/320 [==============================] - 0s 842us/step - loss: 0.3904 - accuracy: 0.8424\n",
      "Epoch 159/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3930 - accuracy: 0.8430\n",
      "Epoch 160/500\n",
      "320/320 [==============================] - 0s 823us/step - loss: 0.3887 - accuracy: 0.8430\n",
      "Epoch 161/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3896 - accuracy: 0.8455\n",
      "Epoch 162/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3903 - accuracy: 0.8434\n",
      "Epoch 163/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3852 - accuracy: 0.8447\n",
      "Epoch 164/500\n",
      "320/320 [==============================] - 0s 894us/step - loss: 0.3875 - accuracy: 0.8416\n",
      "Epoch 165/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3863 - accuracy: 0.8453\n",
      "Epoch 166/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3892 - accuracy: 0.8440\n",
      "Epoch 167/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3846 - accuracy: 0.8440\n",
      "Epoch 168/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3844 - accuracy: 0.8454\n",
      "Epoch 169/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3853 - accuracy: 0.8434\n",
      "Epoch 170/500\n",
      "320/320 [==============================] - 0s 856us/step - loss: 0.3859 - accuracy: 0.8459\n",
      "Epoch 171/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3869 - accuracy: 0.8449\n",
      "Epoch 172/500\n",
      "320/320 [==============================] - 0s 848us/step - loss: 0.3874 - accuracy: 0.8444\n",
      "Epoch 173/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3837 - accuracy: 0.8447\n",
      "Epoch 174/500\n",
      "320/320 [==============================] - 0s 839us/step - loss: 0.3841 - accuracy: 0.8421\n",
      "Epoch 175/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3822 - accuracy: 0.8455\n",
      "Epoch 176/500\n",
      "320/320 [==============================] - 0s 851us/step - loss: 0.3816 - accuracy: 0.8480\n",
      "Epoch 177/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3840 - accuracy: 0.8460\n",
      "Epoch 178/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3862 - accuracy: 0.8424\n",
      "Epoch 179/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3837 - accuracy: 0.8457\n",
      "Epoch 180/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3820 - accuracy: 0.8485\n",
      "Epoch 181/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3868 - accuracy: 0.8435\n",
      "Epoch 182/500\n",
      "320/320 [==============================] - 0s 871us/step - loss: 0.3811 - accuracy: 0.8497\n",
      "Epoch 183/500\n",
      "320/320 [==============================] - 0s 827us/step - loss: 0.3823 - accuracy: 0.8468\n",
      "Epoch 184/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3762 - accuracy: 0.8491\n",
      "Epoch 185/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3830 - accuracy: 0.8468\n",
      "Epoch 186/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3815 - accuracy: 0.8451\n",
      "Epoch 187/500\n",
      "320/320 [==============================] - 0s 810us/step - loss: 0.3793 - accuracy: 0.8470\n",
      "Epoch 188/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3793 - accuracy: 0.8499\n",
      "Epoch 189/500\n",
      "320/320 [==============================] - 0s 865us/step - loss: 0.3791 - accuracy: 0.8475\n",
      "Epoch 190/500\n",
      "320/320 [==============================] - 0s 826us/step - loss: 0.3818 - accuracy: 0.8455\n",
      "Epoch 191/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3784 - accuracy: 0.8471\n",
      "Epoch 192/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3854 - accuracy: 0.8454\n",
      "Epoch 193/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3781 - accuracy: 0.8484\n",
      "Epoch 194/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3832 - accuracy: 0.8460\n",
      "Epoch 195/500\n",
      "320/320 [==============================] - 0s 865us/step - loss: 0.3824 - accuracy: 0.8484\n",
      "Epoch 196/500\n",
      "320/320 [==============================] - 0s 826us/step - loss: 0.3774 - accuracy: 0.8505\n",
      "Epoch 197/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3797 - accuracy: 0.8496\n",
      "Epoch 198/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3792 - accuracy: 0.8466\n",
      "Epoch 199/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3811 - accuracy: 0.8503\n",
      "Epoch 200/500\n",
      "320/320 [==============================] - 0s 834us/step - loss: 0.3827 - accuracy: 0.8443\n",
      "Epoch 201/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3794 - accuracy: 0.8456\n",
      "Epoch 202/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3814 - accuracy: 0.8468\n",
      "Epoch 203/500\n",
      "320/320 [==============================] - 0s 842us/step - loss: 0.3812 - accuracy: 0.8466\n",
      "Epoch 204/500\n",
      "320/320 [==============================] - 0s 853us/step - loss: 0.3787 - accuracy: 0.8500\n",
      "Epoch 205/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3869 - accuracy: 0.8455\n",
      "Epoch 206/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3804 - accuracy: 0.8500\n",
      "Epoch 207/500\n",
      "320/320 [==============================] - 0s 859us/step - loss: 0.3826 - accuracy: 0.8479\n",
      "Epoch 208/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3795 - accuracy: 0.8485\n",
      "Epoch 209/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3798 - accuracy: 0.8509\n",
      "Epoch 210/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3762 - accuracy: 0.8489\n",
      "Epoch 211/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3850 - accuracy: 0.8449\n",
      "Epoch 212/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3767 - accuracy: 0.8506\n",
      "Epoch 213/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3798 - accuracy: 0.8478\n",
      "Epoch 214/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3839 - accuracy: 0.8479\n",
      "Epoch 215/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3777 - accuracy: 0.8499\n",
      "Epoch 216/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3755 - accuracy: 0.8482\n",
      "Epoch 217/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3803 - accuracy: 0.8487\n",
      "Epoch 218/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3792 - accuracy: 0.8499\n",
      "Epoch 219/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.3830 - accuracy: 0.8450\n",
      "Epoch 220/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3825 - accuracy: 0.8464\n",
      "Epoch 221/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3789 - accuracy: 0.8529\n",
      "Epoch 222/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3821 - accuracy: 0.8487\n",
      "Epoch 223/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3760 - accuracy: 0.8512\n",
      "Epoch 224/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3800 - accuracy: 0.8495\n",
      "Epoch 225/500\n",
      "320/320 [==============================] - 0s 855us/step - loss: 0.3805 - accuracy: 0.8466\n",
      "Epoch 226/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3835 - accuracy: 0.8493\n",
      "Epoch 227/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3802 - accuracy: 0.8511\n",
      "Epoch 228/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3784 - accuracy: 0.8522\n",
      "Epoch 229/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3847 - accuracy: 0.8497\n",
      "Epoch 230/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3770 - accuracy: 0.8500\n",
      "Epoch 231/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.3809 - accuracy: 0.8510\n",
      "Epoch 232/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3799 - accuracy: 0.8476\n",
      "Epoch 233/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3793 - accuracy: 0.8496\n",
      "Epoch 234/500\n",
      "320/320 [==============================] - 0s 837us/step - loss: 0.3784 - accuracy: 0.8505\n",
      "Epoch 235/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3782 - accuracy: 0.8533\n",
      "Epoch 236/500\n",
      "320/320 [==============================] - 0s 863us/step - loss: 0.3885 - accuracy: 0.8451\n",
      "Epoch 237/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3779 - accuracy: 0.8525\n",
      "Epoch 238/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3821 - accuracy: 0.8496\n",
      "Epoch 239/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3802 - accuracy: 0.8489\n",
      "Epoch 240/500\n",
      "320/320 [==============================] - 0s 853us/step - loss: 0.3785 - accuracy: 0.8484\n",
      "Epoch 241/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3809 - accuracy: 0.8485\n",
      "Epoch 242/500\n",
      "320/320 [==============================] - 0s 904us/step - loss: 0.3863 - accuracy: 0.8489\n",
      "Epoch 243/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3817 - accuracy: 0.8480\n",
      "Epoch 244/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3822 - accuracy: 0.8503\n",
      "Epoch 245/500\n",
      "320/320 [==============================] - 0s 863us/step - loss: 0.3808 - accuracy: 0.8491\n",
      "Epoch 246/500\n",
      "320/320 [==============================] - 0s 853us/step - loss: 0.3764 - accuracy: 0.8479\n",
      "Epoch 247/500\n",
      "320/320 [==============================] - 0s 898us/step - loss: 0.3775 - accuracy: 0.8543\n",
      "Epoch 248/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3811 - accuracy: 0.8509\n",
      "Epoch 249/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3793 - accuracy: 0.8496\n",
      "Epoch 250/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3815 - accuracy: 0.8512\n",
      "Epoch 251/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3796 - accuracy: 0.8506\n",
      "Epoch 252/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3797 - accuracy: 0.8509\n",
      "Epoch 253/500\n",
      "320/320 [==============================] - 0s 873us/step - loss: 0.3822 - accuracy: 0.8516\n",
      "Epoch 254/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3861 - accuracy: 0.8500\n",
      "Epoch 255/500\n",
      "320/320 [==============================] - 0s 863us/step - loss: 0.3811 - accuracy: 0.8482\n",
      "Epoch 256/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3803 - accuracy: 0.8485\n",
      "Epoch 257/500\n",
      "320/320 [==============================] - 0s 846us/step - loss: 0.3804 - accuracy: 0.8515\n",
      "Epoch 258/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3738 - accuracy: 0.8524\n",
      "Epoch 259/500\n",
      "320/320 [==============================] - 0s 905us/step - loss: 0.3833 - accuracy: 0.8489\n",
      "Epoch 260/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3767 - accuracy: 0.8533\n",
      "Epoch 261/500\n",
      "320/320 [==============================] - 0s 863us/step - loss: 0.3807 - accuracy: 0.8520\n",
      "Epoch 262/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3771 - accuracy: 0.8524\n",
      "Epoch 263/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.3754 - accuracy: 0.8514\n",
      "Epoch 264/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3807 - accuracy: 0.8518\n",
      "Epoch 265/500\n",
      "320/320 [==============================] - 0s 861us/step - loss: 0.3774 - accuracy: 0.8521\n",
      "Epoch 266/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3791 - accuracy: 0.8533\n",
      "Epoch 267/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3794 - accuracy: 0.8520\n",
      "Epoch 268/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3843 - accuracy: 0.8497\n",
      "Epoch 269/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3823 - accuracy: 0.8491\n",
      "Epoch 270/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3766 - accuracy: 0.8512\n",
      "Epoch 271/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3771 - accuracy: 0.8500\n",
      "Epoch 272/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3791 - accuracy: 0.8533\n",
      "Epoch 273/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3796 - accuracy: 0.8503\n",
      "Epoch 274/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3833 - accuracy: 0.8515\n",
      "Epoch 275/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3801 - accuracy: 0.8497\n",
      "Epoch 276/500\n",
      "320/320 [==============================] - 0s 858us/step - loss: 0.3793 - accuracy: 0.8491\n",
      "Epoch 277/500\n",
      "320/320 [==============================] - 0s 810us/step - loss: 0.3820 - accuracy: 0.8520\n",
      "Epoch 278/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3775 - accuracy: 0.8541\n",
      "Epoch 279/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3817 - accuracy: 0.8506\n",
      "Epoch 280/500\n",
      "320/320 [==============================] - 0s 803us/step - loss: 0.3761 - accuracy: 0.8539\n",
      "Epoch 281/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3753 - accuracy: 0.8511\n",
      "Epoch 282/500\n",
      "320/320 [==============================] - 0s 867us/step - loss: 0.3821 - accuracy: 0.8504\n",
      "Epoch 283/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3778 - accuracy: 0.8512\n",
      "Epoch 284/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3768 - accuracy: 0.8520\n",
      "Epoch 285/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3783 - accuracy: 0.8516\n",
      "Epoch 286/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3741 - accuracy: 0.8540\n",
      "Epoch 287/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3817 - accuracy: 0.8521\n",
      "Epoch 288/500\n",
      "320/320 [==============================] - 0s 863us/step - loss: 0.3774 - accuracy: 0.8543\n",
      "Epoch 289/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3819 - accuracy: 0.8537\n",
      "Epoch 290/500\n",
      "320/320 [==============================] - 0s 826us/step - loss: 0.3786 - accuracy: 0.8545\n",
      "Epoch 291/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3794 - accuracy: 0.8514\n",
      "Epoch 292/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3744 - accuracy: 0.8508\n",
      "Epoch 293/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3776 - accuracy: 0.8525\n",
      "Epoch 294/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3762 - accuracy: 0.8543\n",
      "Epoch 295/500\n",
      "320/320 [==============================] - 0s 823us/step - loss: 0.3790 - accuracy: 0.8511\n",
      "Epoch 296/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3831 - accuracy: 0.8508\n",
      "Epoch 297/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3790 - accuracy: 0.8512\n",
      "Epoch 298/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3739 - accuracy: 0.8531\n",
      "Epoch 299/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3742 - accuracy: 0.8504\n",
      "Epoch 300/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3764 - accuracy: 0.8510\n",
      "Epoch 301/500\n",
      "320/320 [==============================] - 0s 848us/step - loss: 0.3771 - accuracy: 0.8525\n",
      "Epoch 302/500\n",
      "320/320 [==============================] - 0s 837us/step - loss: 0.3773 - accuracy: 0.8508\n",
      "Epoch 303/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3802 - accuracy: 0.8487\n",
      "Epoch 304/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3797 - accuracy: 0.8535\n",
      "Epoch 305/500\n",
      "320/320 [==============================] - 0s 986us/step - loss: 0.3782 - accuracy: 0.8510\n",
      "Epoch 306/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3771 - accuracy: 0.8518\n",
      "Epoch 307/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3804 - accuracy: 0.8503\n",
      "Epoch 308/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3719 - accuracy: 0.8501\n",
      "Epoch 309/500\n",
      "320/320 [==============================] - 0s 815us/step - loss: 0.3733 - accuracy: 0.8497\n",
      "Epoch 310/500\n",
      "320/320 [==============================] - 0s 852us/step - loss: 0.3756 - accuracy: 0.8515\n",
      "Epoch 311/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3761 - accuracy: 0.8516\n",
      "Epoch 312/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3790 - accuracy: 0.8510\n",
      "Epoch 313/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3818 - accuracy: 0.8512\n",
      "Epoch 314/500\n",
      "320/320 [==============================] - 0s 807us/step - loss: 0.3771 - accuracy: 0.8525\n",
      "Epoch 315/500\n",
      "320/320 [==============================] - 0s 874us/step - loss: 0.3734 - accuracy: 0.8525\n",
      "Epoch 316/500\n",
      "320/320 [==============================] - 0s 817us/step - loss: 0.3806 - accuracy: 0.8506\n",
      "Epoch 317/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3759 - accuracy: 0.8543\n",
      "Epoch 318/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3707 - accuracy: 0.8531\n",
      "Epoch 319/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3785 - accuracy: 0.8529\n",
      "Epoch 320/500\n",
      "320/320 [==============================] - 0s 864us/step - loss: 0.3795 - accuracy: 0.8503\n",
      "Epoch 321/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3726 - accuracy: 0.8522\n",
      "Epoch 322/500\n",
      "320/320 [==============================] - 0s 823us/step - loss: 0.3805 - accuracy: 0.8524\n",
      "Epoch 323/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3743 - accuracy: 0.8522\n",
      "Epoch 324/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3743 - accuracy: 0.8506\n",
      "Epoch 325/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3771 - accuracy: 0.8500\n",
      "Epoch 326/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3810 - accuracy: 0.8493\n",
      "Epoch 327/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3742 - accuracy: 0.8522\n",
      "Epoch 328/500\n",
      "320/320 [==============================] - 0s 824us/step - loss: 0.3784 - accuracy: 0.8516\n",
      "Epoch 329/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3785 - accuracy: 0.8466\n",
      "Epoch 330/500\n",
      "320/320 [==============================] - 0s 861us/step - loss: 0.3745 - accuracy: 0.8509\n",
      "Epoch 331/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3776 - accuracy: 0.8494\n",
      "Epoch 332/500\n",
      "320/320 [==============================] - 0s 827us/step - loss: 0.3794 - accuracy: 0.8499\n",
      "Epoch 333/500\n",
      "320/320 [==============================] - 0s 810us/step - loss: 0.3752 - accuracy: 0.8511\n",
      "Epoch 334/500\n",
      "320/320 [==============================] - 0s 807us/step - loss: 0.3749 - accuracy: 0.8547\n",
      "Epoch 335/500\n",
      "320/320 [==============================] - 0s 869us/step - loss: 0.3822 - accuracy: 0.8503\n",
      "Epoch 336/500\n",
      "320/320 [==============================] - 0s 830us/step - loss: 0.3811 - accuracy: 0.8511\n",
      "Epoch 337/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3775 - accuracy: 0.8504\n",
      "Epoch 338/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3811 - accuracy: 0.8496\n",
      "Epoch 339/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3786 - accuracy: 0.8506\n",
      "Epoch 340/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3726 - accuracy: 0.8512\n",
      "Epoch 341/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3759 - accuracy: 0.8510\n",
      "Epoch 342/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3786 - accuracy: 0.8505\n",
      "Epoch 343/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3769 - accuracy: 0.8505\n",
      "Epoch 344/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3750 - accuracy: 0.8511\n",
      "Epoch 345/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3801 - accuracy: 0.8490\n",
      "Epoch 346/500\n",
      "320/320 [==============================] - 0s 851us/step - loss: 0.3778 - accuracy: 0.8501\n",
      "Epoch 347/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3781 - accuracy: 0.8514\n",
      "Epoch 348/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3832 - accuracy: 0.8484\n",
      "Epoch 349/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3762 - accuracy: 0.8522\n",
      "Epoch 350/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3759 - accuracy: 0.8496\n",
      "Epoch 351/500\n",
      "320/320 [==============================] - 0s 866us/step - loss: 0.3755 - accuracy: 0.8508\n",
      "Epoch 352/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3772 - accuracy: 0.8539\n",
      "Epoch 353/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3738 - accuracy: 0.8520\n",
      "Epoch 354/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3787 - accuracy: 0.8506\n",
      "Epoch 355/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3806 - accuracy: 0.8497\n",
      "Epoch 356/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3818 - accuracy: 0.8470\n",
      "Epoch 357/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3733 - accuracy: 0.8540\n",
      "Epoch 358/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3807 - accuracy: 0.8559\n",
      "Epoch 359/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3784 - accuracy: 0.8508\n",
      "Epoch 360/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3758 - accuracy: 0.8487\n",
      "Epoch 361/500\n",
      "320/320 [==============================] - 0s 885us/step - loss: 0.3772 - accuracy: 0.8512\n",
      "Epoch 362/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3796 - accuracy: 0.8514\n",
      "Epoch 363/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3745 - accuracy: 0.8518\n",
      "Epoch 364/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3761 - accuracy: 0.8505\n",
      "Epoch 365/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3806 - accuracy: 0.8521\n",
      "Epoch 366/500\n",
      "320/320 [==============================] - 0s 873us/step - loss: 0.3750 - accuracy: 0.8525\n",
      "Epoch 367/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3741 - accuracy: 0.8525\n",
      "Epoch 368/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3746 - accuracy: 0.8537\n",
      "Epoch 369/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3784 - accuracy: 0.8544\n",
      "Epoch 370/500\n",
      "320/320 [==============================] - 0s 843us/step - loss: 0.3751 - accuracy: 0.8526\n",
      "Epoch 371/500\n",
      "320/320 [==============================] - 0s 876us/step - loss: 0.3759 - accuracy: 0.8533\n",
      "Epoch 372/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3701 - accuracy: 0.8524\n",
      "Epoch 373/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3778 - accuracy: 0.8497\n",
      "Epoch 374/500\n",
      "320/320 [==============================] - 0s 827us/step - loss: 0.3745 - accuracy: 0.8499\n",
      "Epoch 375/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3742 - accuracy: 0.8494\n",
      "Epoch 376/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3739 - accuracy: 0.8508\n",
      "Epoch 377/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3820 - accuracy: 0.8499\n",
      "Epoch 378/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3779 - accuracy: 0.8495\n",
      "Epoch 379/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3840 - accuracy: 0.8497\n",
      "Epoch 380/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3701 - accuracy: 0.8520\n",
      "Epoch 381/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.3745 - accuracy: 0.8529\n",
      "Epoch 382/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3787 - accuracy: 0.8529\n",
      "Epoch 383/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3744 - accuracy: 0.8526\n",
      "Epoch 384/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3731 - accuracy: 0.8526\n",
      "Epoch 385/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3790 - accuracy: 0.8540\n",
      "Epoch 386/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3740 - accuracy: 0.8519\n",
      "Epoch 387/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3745 - accuracy: 0.8533\n",
      "Epoch 388/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3748 - accuracy: 0.8564\n",
      "Epoch 389/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3748 - accuracy: 0.8496\n",
      "Epoch 390/500\n",
      "320/320 [==============================] - 0s 865us/step - loss: 0.3741 - accuracy: 0.8536\n",
      "Epoch 391/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3823 - accuracy: 0.8519\n",
      "Epoch 392/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3770 - accuracy: 0.8486\n",
      "Epoch 393/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3798 - accuracy: 0.8500\n",
      "Epoch 394/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3761 - accuracy: 0.8515\n",
      "Epoch 395/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.3754 - accuracy: 0.8490\n",
      "Epoch 396/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3820 - accuracy: 0.8518\n",
      "Epoch 397/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3821 - accuracy: 0.8494\n",
      "Epoch 398/500\n",
      "320/320 [==============================] - 0s 839us/step - loss: 0.3772 - accuracy: 0.8497\n",
      "Epoch 399/500\n",
      "320/320 [==============================] - 0s 870us/step - loss: 0.3729 - accuracy: 0.8549\n",
      "Epoch 400/500\n",
      "320/320 [==============================] - 0s 840us/step - loss: 0.3746 - accuracy: 0.8518\n",
      "Epoch 401/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3748 - accuracy: 0.8528\n",
      "Epoch 402/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3756 - accuracy: 0.8512\n",
      "Epoch 403/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3760 - accuracy: 0.8543\n",
      "Epoch 404/500\n",
      "320/320 [==============================] - 0s 869us/step - loss: 0.3784 - accuracy: 0.8521\n",
      "Epoch 405/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3761 - accuracy: 0.8516\n",
      "Epoch 406/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3787 - accuracy: 0.8510\n",
      "Epoch 407/500\n",
      "320/320 [==============================] - 0s 848us/step - loss: 0.3778 - accuracy: 0.8509\n",
      "Epoch 408/500\n",
      "320/320 [==============================] - 0s 879us/step - loss: 0.3808 - accuracy: 0.8520\n",
      "Epoch 409/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3732 - accuracy: 0.8508\n",
      "Epoch 410/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3789 - accuracy: 0.8500\n",
      "Epoch 411/500\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.3763 - accuracy: 0.8511\n",
      "Epoch 412/500\n",
      "320/320 [==============================] - 0s 840us/step - loss: 0.3777 - accuracy: 0.8530\n",
      "Epoch 413/500\n",
      "320/320 [==============================] - 0s 851us/step - loss: 0.3727 - accuracy: 0.8533\n",
      "Epoch 414/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3749 - accuracy: 0.8533\n",
      "Epoch 415/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3738 - accuracy: 0.8533\n",
      "Epoch 416/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3748 - accuracy: 0.8516\n",
      "Epoch 417/500\n",
      "320/320 [==============================] - 0s 859us/step - loss: 0.3730 - accuracy: 0.8522\n",
      "Epoch 418/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3726 - accuracy: 0.8529\n",
      "Epoch 419/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3783 - accuracy: 0.8495\n",
      "Epoch 420/500\n",
      "320/320 [==============================] - 0s 827us/step - loss: 0.3757 - accuracy: 0.8558\n",
      "Epoch 421/500\n",
      "320/320 [==============================] - 0s 845us/step - loss: 0.3759 - accuracy: 0.8521\n",
      "Epoch 422/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.3749 - accuracy: 0.8516\n",
      "Epoch 423/500\n",
      "320/320 [==============================] - 0s 897us/step - loss: 0.3751 - accuracy: 0.8504\n",
      "Epoch 424/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3774 - accuracy: 0.8520\n",
      "Epoch 425/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3828 - accuracy: 0.8491\n",
      "Epoch 426/500\n",
      "320/320 [==============================] - 0s 894us/step - loss: 0.3786 - accuracy: 0.8511\n",
      "Epoch 427/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3761 - accuracy: 0.8481\n",
      "Epoch 428/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3763 - accuracy: 0.8519\n",
      "Epoch 429/500\n",
      "320/320 [==============================] - 0s 821us/step - loss: 0.3804 - accuracy: 0.8491\n",
      "Epoch 430/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3792 - accuracy: 0.8535\n",
      "Epoch 431/500\n",
      "320/320 [==============================] - 0s 871us/step - loss: 0.3719 - accuracy: 0.8509\n",
      "Epoch 432/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3776 - accuracy: 0.8504\n",
      "Epoch 433/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3756 - accuracy: 0.8509\n",
      "Epoch 434/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3733 - accuracy: 0.8562\n",
      "Epoch 435/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3752 - accuracy: 0.8520\n",
      "Epoch 436/500\n",
      "320/320 [==============================] - 0s 859us/step - loss: 0.3771 - accuracy: 0.8497\n",
      "Epoch 437/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3791 - accuracy: 0.8500\n",
      "Epoch 438/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3797 - accuracy: 0.8486\n",
      "Epoch 439/500\n",
      "320/320 [==============================] - 0s 826us/step - loss: 0.3778 - accuracy: 0.8539\n",
      "Epoch 440/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.3722 - accuracy: 0.8497\n",
      "Epoch 441/500\n",
      "320/320 [==============================] - 0s 827us/step - loss: 0.3776 - accuracy: 0.8519\n",
      "Epoch 442/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3733 - accuracy: 0.8540\n",
      "Epoch 443/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3740 - accuracy: 0.8520\n",
      "Epoch 444/500\n",
      "320/320 [==============================] - 0s 858us/step - loss: 0.3773 - accuracy: 0.8499\n",
      "Epoch 445/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3750 - accuracy: 0.8515\n",
      "Epoch 446/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3798 - accuracy: 0.8515\n",
      "Epoch 447/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3737 - accuracy: 0.8533\n",
      "Epoch 448/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3746 - accuracy: 0.8515\n",
      "Epoch 449/500\n",
      "320/320 [==============================] - 0s 865us/step - loss: 0.3796 - accuracy: 0.8494\n",
      "Epoch 450/500\n",
      "320/320 [==============================] - 0s 816us/step - loss: 0.3790 - accuracy: 0.8486\n",
      "Epoch 451/500\n",
      "320/320 [==============================] - 0s 833us/step - loss: 0.3817 - accuracy: 0.8487\n",
      "Epoch 452/500\n",
      "320/320 [==============================] - 0s 828us/step - loss: 0.3746 - accuracy: 0.8526\n",
      "Epoch 453/500\n",
      "320/320 [==============================] - 0s 853us/step - loss: 0.3699 - accuracy: 0.8524\n",
      "Epoch 454/500\n",
      "320/320 [==============================] - 0s 813us/step - loss: 0.3754 - accuracy: 0.8509\n",
      "Epoch 455/500\n",
      "320/320 [==============================] - 0s 819us/step - loss: 0.3773 - accuracy: 0.8493\n",
      "Epoch 456/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3770 - accuracy: 0.8520\n",
      "Epoch 457/500\n",
      "320/320 [==============================] - 0s 895us/step - loss: 0.3840 - accuracy: 0.8491\n",
      "Epoch 458/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3746 - accuracy: 0.8518\n",
      "Epoch 459/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3740 - accuracy: 0.8528\n",
      "Epoch 460/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3752 - accuracy: 0.8525\n",
      "Epoch 461/500\n",
      "320/320 [==============================] - 0s 890us/step - loss: 0.3741 - accuracy: 0.8571\n",
      "Epoch 462/500\n",
      "320/320 [==============================] - 0s 839us/step - loss: 0.3742 - accuracy: 0.8518\n",
      "Epoch 463/500\n",
      "320/320 [==============================] - 0s 845us/step - loss: 0.3757 - accuracy: 0.8530\n",
      "Epoch 464/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3789 - accuracy: 0.8509\n",
      "Epoch 465/500\n",
      "320/320 [==============================] - 0s 829us/step - loss: 0.3776 - accuracy: 0.8508\n",
      "Epoch 466/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.3743 - accuracy: 0.8539\n",
      "Epoch 467/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3715 - accuracy: 0.8531\n",
      "Epoch 468/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3800 - accuracy: 0.8501\n",
      "Epoch 469/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3754 - accuracy: 0.8491\n",
      "Epoch 470/500\n",
      "320/320 [==============================] - 0s 879us/step - loss: 0.3775 - accuracy: 0.8526\n",
      "Epoch 471/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3779 - accuracy: 0.8519\n",
      "Epoch 472/500\n",
      "320/320 [==============================] - 0s 854us/step - loss: 0.3741 - accuracy: 0.8537\n",
      "Epoch 473/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3778 - accuracy: 0.8482\n",
      "Epoch 474/500\n",
      "320/320 [==============================] - 0s 900us/step - loss: 0.3768 - accuracy: 0.8509\n",
      "Epoch 475/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3709 - accuracy: 0.8562\n",
      "Epoch 476/500\n",
      "320/320 [==============================] - 0s 822us/step - loss: 0.3780 - accuracy: 0.8516\n",
      "Epoch 477/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3776 - accuracy: 0.8521\n",
      "Epoch 478/500\n",
      "320/320 [==============================] - 0s 856us/step - loss: 0.3746 - accuracy: 0.8512\n",
      "Epoch 479/500\n",
      "320/320 [==============================] - 0s 844us/step - loss: 0.3761 - accuracy: 0.8524\n",
      "Epoch 480/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3732 - accuracy: 0.8496\n",
      "Epoch 481/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3745 - accuracy: 0.8524\n",
      "Epoch 482/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3792 - accuracy: 0.8489\n",
      "Epoch 483/500\n",
      "320/320 [==============================] - 0s 856us/step - loss: 0.3820 - accuracy: 0.8489\n",
      "Epoch 484/500\n",
      "320/320 [==============================] - 0s 850us/step - loss: 0.3772 - accuracy: 0.8510\n",
      "Epoch 485/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3785 - accuracy: 0.8528\n",
      "Epoch 486/500\n",
      "320/320 [==============================] - 0s 833us/step - loss: 0.3791 - accuracy: 0.8495\n",
      "Epoch 487/500\n",
      "320/320 [==============================] - 0s 872us/step - loss: 0.3760 - accuracy: 0.8530\n",
      "Epoch 488/500\n",
      "320/320 [==============================] - 0s 830us/step - loss: 0.3803 - accuracy: 0.8501\n",
      "Epoch 489/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3763 - accuracy: 0.8530\n",
      "Epoch 490/500\n",
      "320/320 [==============================] - 0s 832us/step - loss: 0.3764 - accuracy: 0.8536\n",
      "Epoch 491/500\n",
      "320/320 [==============================] - 0s 875us/step - loss: 0.3770 - accuracy: 0.8485\n",
      "Epoch 492/500\n",
      "320/320 [==============================] - 0s 860us/step - loss: 0.3774 - accuracy: 0.8536\n",
      "Epoch 493/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3744 - accuracy: 0.8524\n",
      "Epoch 494/500\n",
      "320/320 [==============================] - 0s 857us/step - loss: 0.3787 - accuracy: 0.8501\n",
      "Epoch 495/500\n",
      "320/320 [==============================] - 0s 888us/step - loss: 0.3758 - accuracy: 0.8533\n",
      "Epoch 496/500\n",
      "320/320 [==============================] - 0s 847us/step - loss: 0.3769 - accuracy: 0.8525\n",
      "Epoch 497/500\n",
      "320/320 [==============================] - 0s 838us/step - loss: 0.3767 - accuracy: 0.8522\n",
      "Epoch 498/500\n",
      "320/320 [==============================] - 0s 841us/step - loss: 0.3769 - accuracy: 0.8497\n",
      "Epoch 499/500\n",
      "320/320 [==============================] - 0s 879us/step - loss: 0.3746 - accuracy: 0.8520\n",
      "Epoch 500/500\n",
      "320/320 [==============================] - 0s 835us/step - loss: 0.3787 - accuracy: 0.8533\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Jacob\\AppData\\Local\\Temp\\tmpw4t033ob\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jacob\\AppData\\Local\\Temp\\tmpw4t033ob\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/classifier.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the ANN\n",
    "# The Optimal Parameters for this model is chosen using grid search CV\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and hidden layer\n",
    "classifier.add(Dense(units=6, activation='relu', input_dim=11))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units=6, activation='relu'))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "# Adding the oputput layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# compiling the ANN\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size=25, epochs=500)\n",
    "\n",
    "# save the keras model as an instance\n",
    "classifier.save(\"model/my_model.keras\", overwrite=True)\n",
    "dump(classifier, \"model/classifier.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 788us/step\n",
      "The confusion Matrix is: \n",
      " [[1499   78]\n",
      " [ 190  233]] \n",
      "The accuracy is:  0.866\n"
     ]
    }
   ],
   "source": [
    "# predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The confusion Matrix is: \\n\", conf_matrix,\"\\nThe accuracy is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "from keras.models import load_model\n",
    "\n",
    "scaler = load(\"model/scaler_instance.joblib\")\n",
    "classifier = load_model(\"model/my_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.726998"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting a Single new customer\n",
    "\"\"\"\n",
    "Geography = Bangalore\n",
    "Credit Score = 600\n",
    "Gender = Male\n",
    "Age = 40\n",
    "Tenure = 3\n",
    "Balance = 60000\n",
    "Number of Products = 2\n",
    "Has Credit Card = Yes\n",
    "Is Active Member = Yes\n",
    "Estimated Salary = 50000\n",
    "\"\"\"\n",
    "new_prediction = classifier.predict(scaler.transform(np.array([[1,0,502,0,42,8,159660.8,3,1,0,113931.6]])))\n",
    "new_pred = (new_prediction > 0.5)\n",
    "new_prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 917us/step\n",
      "Accuracy: 0.866\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1577\n",
      "           1       0.75      0.55      0.63       423\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.82      0.75      0.78      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# save the classification report\n",
    "with open(\"model/classification_report.txt\", \"w\") as f:\n",
    "    f.write(f\"Accuracy: {accuracy}\\n\")\n",
    "    f.write(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a heatmap with visible values and greyscale color map\n",
    "plt.figure(figsize=(8,6))  # Adjust the size of the plot\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greys')\n",
    "\n",
    "# Set the labels for x-axis and y-axis\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig(\"model/charts/heatmap.jpg\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
